# app.py
import gradio as gr
import torch
import pandas as pd
from model import SentimentModel, ModelConfig
from transformers import BertTokenizer
import logging
import os

class SentimentAnalyzer:
    def __init__(self, model_path):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
        
        # åˆå§‹åŒ–æ¨¡å‹
        config = ModelConfig()
        config.vocab_size = self.tokenizer.vocab_size
        self.model = SentimentModel(config).to(self.device)
        # åŠ è½½æ¨¡å‹æƒé‡
        checkpoint = torch.load(model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()

    def predict_text(self, text, max_length=128):
        """é¢„æµ‹å•ä¸ªæ–‡æœ¬çš„æƒ…æ„Ÿ"""
        if not text.strip():
            return "è¯·è¾“å…¥è¯„è®ºå†…å®¹åå†è¿›è¡Œåˆ†æã€‚"
            
        # é¢„å¤„ç†æ–‡æœ¬
        encoding = self.tokenizer(
            text,
            add_special_tokens=True,
            max_length=max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        input_ids = encoding['input_ids'].to(self.device)
        attention_mask = encoding['attention_mask'].to(self.device)
        
        # é¢„æµ‹
        with torch.no_grad():
            outputs = self.model(input_ids, attention_mask)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            
        # è·å–é¢„æµ‹ç»“æœå’Œæ¦‚ç‡
        probs = probabilities[0].cpu().numpy()
        sentiment_map = {0: 'æ¶ˆæ', 1: 'ä¸­æ€§', 2: 'ç§¯æ'}
        prediction = sentiment_map[probs.argmax()]
        
        # æ„å»ºç»“æœå­—ç¬¦ä¸²
        result = f"âœ¨ æƒ…æ„Ÿåˆ†æç»“æœï¼š{prediction}\n\n"
        result += "ğŸ“Š æ¦‚ç‡åˆ†å¸ƒï¼š\n"
        result += f"æ¶ˆæ: {probs[0]:.2%}\n"
        result += f"ä¸­æ€§: {probs[1]:.2%}\n"
        result += f"ç§¯æ: {probs[2]:.2%}"# æ·»åŠ æƒ…æ„Ÿæ ‡ç­¾çš„é¢œè‰²æç¤º
        color_map = {
            'æ¶ˆæ': 'ğŸ”´',
            'ä¸­æ€§': 'âšª',
            'ç§¯æ': 'ğŸŸ¢'
        }
        result = f"{color_map[prediction]} {result}"
        
        return result

    def predict_file(self, file):
        """é¢„æµ‹CSVæ–‡ä»¶ä¸­çš„è¯„è®º"""
        if file is None:
            return "è¯·å…ˆä¸Šä¼ CSVæ–‡ä»¶ã€‚"
            
        try:
            df = pd.read_csv(file.name)
            if 'review' not in df.columns:
                return "é”™è¯¯ï¼šCSVæ–‡ä»¶å¿…é¡»åŒ…å«'review'åˆ—"
            
            results = []
            for text in df['review']:
                encoding = self.tokenizer(
                    str(text),
                    add_special_tokens=True,
                    max_length=128,
                    padding='max_length',
                    truncation=True,
                    return_tensors='pt'
                )
                
                input_ids = encoding['input_ids'].to(self.device)
                attention_mask = encoding['attention_mask'].to(self.device)
                
                with torch.no_grad():
                    outputs = self.model(input_ids, attention_mask)
                    _, predicted = torch.max(outputs, 1)
                    results.append(predicted.item())
            
            # æ·»åŠ é¢„æµ‹ç»“æœåˆ°DataFrame
            sentiment_map = {0: 'æ¶ˆæ', 1: 'ä¸­æ€§', 2: 'ç§¯æ'}
            df['é¢„æµ‹æƒ…æ„Ÿ'] = [sentiment_map[pred] for pred in results]
            
            # ä¿å­˜ç»“æœ
            output_path = "é¢„æµ‹ç»“æœ.csv"
            df.to_csv(output_path, index=False)
            return f"âœ… é¢„æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³ {output_path}\n\nğŸ“Š æƒ…æ„Ÿåˆ†å¸ƒç»Ÿè®¡ï¼š\n" + \
                   f"ç§¯æè¯„ä»·ï¼š{(df['é¢„æµ‹æƒ…æ„Ÿ']=='ç§¯æ').sum()} æ¡\n" + \
                   f"ä¸­æ€§è¯„ä»·ï¼š{(df['é¢„æµ‹æƒ…æ„Ÿ']=='ä¸­æ€§').sum()} æ¡\n" + \
                   f"æ¶ˆæè¯„ä»·ï¼š{(df['é¢„æµ‹æƒ…æ„Ÿ']=='æ¶ˆæ').sum()} æ¡"
        except Exception as e:
            return f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}"

def create_interface():
    analyzer = SentimentAnalyzer("checkpoints/best_model.pth")  # ä¿®æ”¹ä¸ºä½ çš„æ¨¡å‹è·¯å¾„
    
    # è‡ªå®šä¹‰CSSæ ·å¼
    custom_css = """
    .gradio-container {
        font-family: "Microsoft YaHei", "å¾®è½¯é›…é»‘", sans-serif !important;
    }
    .markdown-text {
        font-size: 16px !important;
        line-height: 1.5 !important;
    }
    .tab-selected {
        background-color: #2196F3 !important;
        color: white !important;
    }
    """
    
    with gr.Blocks(title="è¯å“è¯„è®ºæƒ…æ„Ÿåˆ†æ", css=custom_css) as interface:
        gr.Markdown("""
        # ğŸ¥ è¯å“è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ
        
        æœ¬ç³»ç»Ÿä½¿ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œå¸®åŠ©æ‚¨åˆ†æè¯å“è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ã€‚
        """)
        
        with gr.Tabs():
            # å•æ–‡æœ¬åˆ†ææ ‡ç­¾é¡µ
            with gr.TabItem("âœï¸ å•æ¡è¯„è®ºåˆ†æ"):
                with gr.Column():
                    text_input = gr.Textbox(
                        label="è¯·è¾“å…¥è¯å“è¯„è®º",
                        placeholder="åœ¨æ­¤è¾“å…¥æ‚¨è¦åˆ†æçš„è¯„è®ºå†…å®¹...",
                        lines=4
                    )
                    text_button = gr.Button("å¼€å§‹åˆ†æ", variant="primary")
                    text_output = gr.Textbox(
                        label="åˆ†æç»“æœ",
                        lines=6
                    )
                
                gr.Markdown("""
                ### ğŸ’¡ ä½¿ç”¨è¯´æ˜
                1. åœ¨æ–‡æœ¬æ¡†ä¸­è¾“å…¥æ‚¨æƒ³è¦åˆ†æçš„è¯å“è¯„è®º
                2. ç‚¹å‡»"å¼€å§‹åˆ†æ"æŒ‰é’®
                3. ç³»ç»Ÿå°†æ˜¾ç¤ºæƒ…æ„Ÿåˆ†æç»“æœå’Œæ¦‚ç‡åˆ†å¸ƒ
                """)
            
            # æ–‡ä»¶åˆ†ææ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ“ æ‰¹é‡è¯„è®ºåˆ†æ"):
                with gr.Column():
                    file_input = gr.File(
                        label="ä¸Šä¼ CSVæ–‡ä»¶",
                        file_types=[".csv"]
                    )
                    file_button = gr.Button("å¼€å§‹åˆ†æ", variant="primary")
                    file_output = gr.Textbox(
                        label="å¤„ç†ç»“æœ",
                        lines=6
                    )
                
                gr.Markdown("""
                ### ğŸ’¡ ä½¿ç”¨è¯´æ˜
                1. å‡†å¤‡åŒ…å«'review'åˆ—çš„CSVæ–‡ä»¶
                2. ä¸Šä¼ æ–‡ä»¶åç‚¹å‡»"å¼€å§‹åˆ†æ"
                3. ç³»ç»Ÿå°†ç”Ÿæˆåˆ†ææŠ¥å‘Šå¹¶ä¿å­˜ç»“æœ
                
                ### ğŸ“‹ æ–‡ä»¶æ ¼å¼è¦æ±‚
                - æ–‡ä»¶æ ¼å¼ï¼šCSV
                - å¿…éœ€åˆ—ï¼šreviewï¼ˆè¯„è®ºå†…å®¹ï¼‰
                - ç¼–ç ï¼šUTF-8
                """)
        
        gr.Markdown("""
        ### ğŸ” å…³äºæƒ…æ„Ÿåˆ†ç±»
        - ğŸŸ¢ ç§¯æï¼šè¡¨ç¤ºç”¨æˆ·å¯¹è¯å“æŒæ­£é¢è¯„ä»·
        - âšª ä¸­æ€§ï¼šè¡¨ç¤ºç”¨æˆ·è¯„ä»·è¾ƒä¸ºä¸­ç«‹
        - ğŸ”´ æ¶ˆæï¼šè¡¨ç¤ºç”¨æˆ·å¯¹è¯å“æŒè´Ÿé¢è¯„ä»·
        
        ### ğŸ‘¨â€ğŸ’» æŠ€æœ¯æ”¯æŒ
        å¦‚æœ‰é—®é¢˜è¯·è”ç³»æŠ€æœ¯æ”¯æŒå›¢é˜Ÿ
        """)
        
        # ç»‘å®šäº‹ä»¶
        text_button.click(
            fn=analyzer.predict_text,
            inputs=text_input,
            outputs=text_output
        )
        
        file_button.click(
            fn=analyzer.predict_file,
            inputs=file_input,
            outputs=file_output
        )
    
    return interface

if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    interface = create_interface()
    interface.launch(
        share=True,
        server_name="0.0.0.0",
        server_port=7860,
        favicon_path="favicon.ico"  # å¦‚æœæœ‰å›¾æ ‡çš„è¯
    )